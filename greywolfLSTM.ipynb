{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "greywolfLSTMSOLAR_W0(24).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manav-Gupta/Solar-Irradiance-Bio-Inspired/blob/main/greywolfLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v37GPr0xQ0sm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "e49f344a-b25e-4c03-c636-a61dc2d365bc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz53BgcyQ2Cn"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvUYj-R7Rfg1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "d1b8597e-35df-4228-aecd-371698ea092a"
      },
      "source": [
        "dataset=pd.read_csv('drive/My Drive/Colab Notebooks/BA_Combined.csv')\n",
        "dataset.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "      <th>Minute</th>\n",
              "      <th>DHI</th>\n",
              "      <th>DNI</th>\n",
              "      <th>GHI</th>\n",
              "      <th>Dew Point</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Pressure</th>\n",
              "      <th>Relative Humidity</th>\n",
              "      <th>Wind Direction</th>\n",
              "      <th>Wind Speed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-5</td>\n",
              "      <td>11.852440</td>\n",
              "      <td>996.147217</td>\n",
              "      <td>29.790052</td>\n",
              "      <td>36.635731</td>\n",
              "      <td>2.722316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-5</td>\n",
              "      <td>11.225597</td>\n",
              "      <td>996.248657</td>\n",
              "      <td>30.983252</td>\n",
              "      <td>38.746647</td>\n",
              "      <td>2.707211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-5</td>\n",
              "      <td>10.658190</td>\n",
              "      <td>995.821533</td>\n",
              "      <td>32.399748</td>\n",
              "      <td>41.129784</td>\n",
              "      <td>2.798367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-4</td>\n",
              "      <td>10.129504</td>\n",
              "      <td>995.645081</td>\n",
              "      <td>34.192746</td>\n",
              "      <td>44.009598</td>\n",
              "      <td>2.898466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-4</td>\n",
              "      <td>9.635840</td>\n",
              "      <td>995.924561</td>\n",
              "      <td>36.213530</td>\n",
              "      <td>47.319065</td>\n",
              "      <td>2.890179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2010</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-4</td>\n",
              "      <td>13.329075</td>\n",
              "      <td>996.727173</td>\n",
              "      <td>29.696787</td>\n",
              "      <td>49.007072</td>\n",
              "      <td>3.624711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2010</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-3</td>\n",
              "      <td>12.871681</td>\n",
              "      <td>997.495850</td>\n",
              "      <td>31.083023</td>\n",
              "      <td>57.249115</td>\n",
              "      <td>3.618878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2010</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-3</td>\n",
              "      <td>13.520990</td>\n",
              "      <td>998.175964</td>\n",
              "      <td>31.173157</td>\n",
              "      <td>64.765450</td>\n",
              "      <td>3.562192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2010</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>30</td>\n",
              "      <td>80</td>\n",
              "      <td>292</td>\n",
              "      <td>135</td>\n",
              "      <td>-2</td>\n",
              "      <td>16.388988</td>\n",
              "      <td>998.849304</td>\n",
              "      <td>27.988229</td>\n",
              "      <td>70.387955</td>\n",
              "      <td>3.084073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2010</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>30</td>\n",
              "      <td>118</td>\n",
              "      <td>577</td>\n",
              "      <td>331</td>\n",
              "      <td>0</td>\n",
              "      <td>19.753776</td>\n",
              "      <td>999.441589</td>\n",
              "      <td>25.638371</td>\n",
              "      <td>72.587616</td>\n",
              "      <td>2.419390</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Year  Month  Day  ...  Relative Humidity  Wind Direction  Wind Speed\n",
              "0  2010      1    1  ...          29.790052       36.635731    2.722316\n",
              "1  2010      1    1  ...          30.983252       38.746647    2.707211\n",
              "2  2010      1    1  ...          32.399748       41.129784    2.798367\n",
              "3  2010      1    1  ...          34.192746       44.009598    2.898466\n",
              "4  2010      1    1  ...          36.213530       47.319065    2.890179\n",
              "5  2010      1    1  ...          29.696787       49.007072    3.624711\n",
              "6  2010      1    1  ...          31.083023       57.249115    3.618878\n",
              "7  2010      1    1  ...          31.173157       64.765450    3.562192\n",
              "8  2010      1    1  ...          27.988229       70.387955    3.084073\n",
              "9  2010      1    1  ...          25.638371       72.587616    2.419390\n",
              "\n",
              "[10 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fhCtQeHRwNy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "outputId": "e3b956b9-fb9a-49c7-d4bf-2c3edd283156"
      },
      "source": [
        "# importing all the required libraries\n",
        "from math import sqrt\n",
        "import keras\n",
        "from numpy import concatenate\n",
        "from matplotlib import pyplot\n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import Adam\n",
        "from datetime import datetime\n",
        "dataset=pd.read_csv('drive/My Drive/Colab Notebooks/BA_Combined.csv')\n",
        "#Removing unnecessary data\n",
        "dataset.drop('Minute',axis=1,inplace=True)\n",
        "dataset.drop('Year',axis=1,inplace=True)\n",
        "dataset.drop('DHI',axis=1,inplace=True)\n",
        "dataset.drop('DNI',axis=1,inplace=True)\n",
        "dataset.drop('Wind Direction',axis=1,inplace=True)\n",
        "dataset.columns=['Month','Day','Hour','GHI','Dew Point','Temperature','Pressure','Relative Humidity','Wind Speed']\n",
        "dataset = dataset[['Month','Day','Hour','GHI','Dew Point','Temperature','Pressure','Relative Humidity','Wind Speed']]\n",
        "print(dataset.head(20))\n",
        "\n",
        "dataset.to_csv('final.csv')\n",
        "plt.plot(dataset['GHI'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    Month  Day  Hour  ...    Pressure  Relative Humidity  Wind Speed\n",
            "0       1    1     0  ...  996.147217          29.790052    2.722316\n",
            "1       1    1     1  ...  996.248657          30.983252    2.707211\n",
            "2       1    1     2  ...  995.821533          32.399748    2.798367\n",
            "3       1    1     3  ...  995.645081          34.192746    2.898466\n",
            "4       1    1     4  ...  995.924561          36.213530    2.890179\n",
            "5       1    1     5  ...  996.727173          29.696787    3.624711\n",
            "6       1    1     6  ...  997.495850          31.083023    3.618878\n",
            "7       1    1     7  ...  998.175964          31.173157    3.562192\n",
            "8       1    1     8  ...  998.849304          27.988229    3.084073\n",
            "9       1    1     9  ...  999.441589          25.638371    2.419390\n",
            "10      1    1    10  ...  999.189270          21.699108    2.170230\n",
            "11      1    1    11  ...  998.304016          18.483890    1.936101\n",
            "12      1    1    12  ...  997.064331          17.682752    1.393144\n",
            "13      1    1    13  ...  996.438904          17.630112    0.928905\n",
            "14      1    1    14  ...  995.764038          18.012171    0.454455\n",
            "15      1    1    15  ...  995.302429          19.112631    0.463374\n",
            "16      1    1    16  ...  995.030701          22.107524    1.052359\n",
            "17      1    1    17  ...  995.012085          32.798620    1.964765\n",
            "18      1    1    18  ...  995.603699          26.297512    2.885018\n",
            "19      1    1    19  ...  995.768982          26.120752    3.588166\n",
            "\n",
            "[20 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f80eb7ecf98>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx9BWoN6pcDH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d632ec13-9ab1-4df1-a364-1f90e9e8ac0d"
      },
      "source": [
        "dataset=read_csv('final.csv',header=0,index_col=0)\n",
        "dataset1=dataset.values\n",
        "dataset2=dataset['GHI'].values\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "      <th>GHI</th>\n",
              "      <th>Dew Point</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Pressure</th>\n",
              "      <th>Relative Humidity</th>\n",
              "      <th>Wind Speed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-5</td>\n",
              "      <td>11.852440</td>\n",
              "      <td>996.147217</td>\n",
              "      <td>29.790052</td>\n",
              "      <td>2.722316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-5</td>\n",
              "      <td>11.225597</td>\n",
              "      <td>996.248657</td>\n",
              "      <td>30.983252</td>\n",
              "      <td>2.707211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-5</td>\n",
              "      <td>10.658190</td>\n",
              "      <td>995.821533</td>\n",
              "      <td>32.399748</td>\n",
              "      <td>2.798367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>-4</td>\n",
              "      <td>10.129504</td>\n",
              "      <td>995.645081</td>\n",
              "      <td>34.192746</td>\n",
              "      <td>2.898466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>-4</td>\n",
              "      <td>9.635840</td>\n",
              "      <td>995.924560</td>\n",
              "      <td>36.213530</td>\n",
              "      <td>2.890179</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Month  Day  Hour  ...    Pressure  Relative Humidity  Wind Speed\n",
              "0      1    1     0  ...  996.147217          29.790052    2.722316\n",
              "1      1    1     1  ...  996.248657          30.983252    2.707211\n",
              "2      1    1     2  ...  995.821533          32.399748    2.798367\n",
              "3      1    1     3  ...  995.645081          34.192746    2.898466\n",
              "4      1    1     4  ...  995.924560          36.213530    2.890179\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcrdFR3rLHOC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f2d19955-cc4a-43a8-e023-314e9d157ac5"
      },
      "source": [
        "#Scaling data\n",
        "scale_x = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_x=scale_x.fit_transform(dataset1)\n",
        "print(scaled_x.shape)\n",
        "\n",
        "dataset2=dataset2.reshape(-1, 1)\n",
        "scale_y = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_y=scale_y.fit_transform(dataset2)\n",
        "print(scaled_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(43800, 9)\n",
            "(43800, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1GZazJU4bB6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a939a35-371c-4f52-db8e-bccea1447379"
      },
      "source": [
        "# vector to matrix conversion function for weights matrix\n",
        "x=list()\n",
        "y=list()\n",
        "for i in range(len(dataset)-25):\n",
        "  xx=list()\n",
        "  for j in range(0,24,1):\n",
        "    value=scaled_x[i+j]\n",
        "    xx.append(value)\n",
        "  x.append(xx)\n",
        "  yy=scaled_y[i+24]\n",
        "  y.append(yy)\n",
        "x=np.array(x)\n",
        "y=np.array(y)\n",
        "print(x.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(43775, 24, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLPGpKY53VMo"
      },
      "source": [
        "#Splitting data into training 70% , testing 15% and validation 15%\n",
        "n_train_hours = 32831\n",
        "n_valid_hours = 37208\n",
        "\n",
        "train_x = x[:n_train_hours]\n",
        "test_x = x[n_valid_hours:]\n",
        "valid_x= x[n_train_hours:n_valid_hours]\n",
        "\n",
        "train_y = y[:n_train_hours]\n",
        "test_y = y[n_valid_hours:]\n",
        "valid_y= y[n_train_hours:n_valid_hours]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WAfASPpzmeG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "ddd4495e-c147-4f99-9008-8f0f536c8260"
      },
      "source": [
        "#Declaration of model\n",
        "model = Sequential()\n",
        "#adding LSTM layer\n",
        "model.add(LSTM(64, input_shape=(24,9),kernel_initializer='truncated_normal'))\n",
        "model.add(Dense(1,activation='linear'))\n",
        "model.compile(loss='mae', optimizer=Adam(lr=0.01))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlh0sqKpvj2g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "7b1cb40f-aa79-4460-9f3d-62b0b84e45e8"
      },
      "source": [
        "#Defining the weights\n",
        "weight1=model.get_weights()\n",
        "w0=weight1[0]\n",
        "w1=weight1[1]\n",
        "w2=weight1[2]\n",
        "w3=weight1[3]\n",
        "W0=w0\n",
        "W1=w1\n",
        "W3=w3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQaT2OoJxu7r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "dd1e7881-7699-4155-a02d-ab086a120237"
      },
      "source": [
        "print(w0.shape)\n",
        "print(w1.shape)\n",
        "print(w2.shape)\n",
        "print(w3.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9, 256)\n",
            "(64, 256)\n",
            "(256,)\n",
            "(64, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lURCg3oDCvl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f01a9f07-3588-4574-8ca2-f3007872eeb4"
      },
      "source": [
        "\n",
        "w=[]\n",
        "for i in range(w0.shape[0]):\n",
        "  for j in range(w0.shape[1]):\n",
        "    value=w0[i][j]\n",
        "    w.append(value)\n",
        "for i in range(w1.shape[0]):\n",
        "  for j in range(w1.shape[1]):\n",
        "    value=w1[i][j]\n",
        "    w.append(value)\n",
        "for i in range(w2.shape[0]):\n",
        "    value=w2[i]\n",
        "    w.append(value)\n",
        "for i in range(w3.shape[0]):\n",
        "  for j in range(w3.shape[1]):\n",
        "    value=w3[i][j]\n",
        "    w.append(value)            \n",
        "w    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.092477284,\n",
              " 0.0035393909,\n",
              " 0.009757009,\n",
              " -0.0013124909,\n",
              " -0.016842175,\n",
              " -0.01083112,\n",
              " -0.019820591,\n",
              " -0.08686286,\n",
              " 0.01339906,\n",
              " 0.031667907,\n",
              " -0.043451406,\n",
              " 0.020977197,\n",
              " 0.047793876,\n",
              " -0.0048315376,\n",
              " -0.024574684,\n",
              " -0.022003593,\n",
              " -0.054907084,\n",
              " 0.012285565,\n",
              " 0.049047157,\n",
              " -0.02313113,\n",
              " 0.040668413,\n",
              " 0.032183927,\n",
              " -0.031416025,\n",
              " 0.0016808062,\n",
              " 0.0754724,\n",
              " -0.068932615,\n",
              " 0.0103701865,\n",
              " 0.06754502,\n",
              " -0.003309775,\n",
              " 0.041151486,\n",
              " -0.044741027,\n",
              " 0.06897512,\n",
              " -0.0053674695,\n",
              " -0.005411576,\n",
              " -0.02015667,\n",
              " 0.027785823,\n",
              " -0.024853684,\n",
              " 0.02608884,\n",
              " -0.021388602,\n",
              " -0.020471359,\n",
              " -0.06011048,\n",
              " -0.019240089,\n",
              " 0.011009677,\n",
              " -0.062361117,\n",
              " 0.03119078,\n",
              " -0.027341817,\n",
              " -0.05976206,\n",
              " -0.011631878,\n",
              " 0.029728932,\n",
              " 0.037799325,\n",
              " -0.014522383,\n",
              " -0.011361248,\n",
              " 0.028317386,\n",
              " 0.024368687,\n",
              " 0.02933445,\n",
              " -0.00047281088,\n",
              " 0.03478923,\n",
              " -0.03437031,\n",
              " -0.073434375,\n",
              " -0.05222198,\n",
              " 0.027963927,\n",
              " 0.06833234,\n",
              " -0.0005711544,\n",
              " 0.052932184,\n",
              " 0.04741606,\n",
              " -0.049052898,\n",
              " 0.01202387,\n",
              " 0.00041458584,\n",
              " -0.031217743,\n",
              " -0.013515298,\n",
              " 0.007897164,\n",
              " -0.010017804,\n",
              " 0.08254893,\n",
              " 0.016309664,\n",
              " 0.090077035,\n",
              " -0.02078306,\n",
              " 0.044270508,\n",
              " -0.037235733,\n",
              " -0.017399317,\n",
              " -0.08932265,\n",
              " 0.04934903,\n",
              " -0.025542894,\n",
              " -0.064510666,\n",
              " 0.024245089,\n",
              " -0.019032812,\n",
              " 0.003785392,\n",
              " 0.0351651,\n",
              " -0.012270476,\n",
              " 0.08849564,\n",
              " 0.0143172145,\n",
              " 0.010514466,\n",
              " 0.016115708,\n",
              " -0.010491075,\n",
              " 0.030340184,\n",
              " 0.0034171504,\n",
              " 0.016510991,\n",
              " 0.040917534,\n",
              " 0.056593128,\n",
              " -0.004893319,\n",
              " 0.064668976,\n",
              " -0.01314267,\n",
              " 0.031149013,\n",
              " 0.0976642,\n",
              " -0.04733141,\n",
              " 0.041292552,\n",
              " -0.018463563,\n",
              " -0.034418736,\n",
              " -0.015991708,\n",
              " -0.026934037,\n",
              " -0.030492371,\n",
              " 0.08023261,\n",
              " -0.077206545,\n",
              " 0.03245793,\n",
              " -0.09511652,\n",
              " 0.050436307,\n",
              " -0.03038616,\n",
              " 0.029370928,\n",
              " -0.021410042,\n",
              " -0.017459404,\n",
              " 0.0057312003,\n",
              " -0.0070039826,\n",
              " -0.061497252,\n",
              " -0.016855055,\n",
              " 0.050346415,\n",
              " -0.06698265,\n",
              " -0.09137235,\n",
              " -0.0634514,\n",
              " 0.0004261628,\n",
              " -0.059713114,\n",
              " 0.037378546,\n",
              " -0.09550393,\n",
              " 0.06494858,\n",
              " -0.010534476,\n",
              " 0.019252067,\n",
              " 0.067642406,\n",
              " -0.04699024,\n",
              " 0.0014678363,\n",
              " 0.0027788808,\n",
              " -0.027489439,\n",
              " 0.003850915,\n",
              " -0.004074897,\n",
              " -0.07089665,\n",
              " -0.03241869,\n",
              " 0.030309072,\n",
              " 0.03329518,\n",
              " -0.019254124,\n",
              " 0.016094143,\n",
              " 0.05203538,\n",
              " -0.07667484,\n",
              " 0.0048337025,\n",
              " -0.027214175,\n",
              " -0.043773346,\n",
              " -0.048366934,\n",
              " -0.07580892,\n",
              " 0.024017034,\n",
              " -0.049957164,\n",
              " 0.024976928,\n",
              " 0.017454283,\n",
              " 0.024321225,\n",
              " -0.008798248,\n",
              " 0.008311306,\n",
              " -0.023993548,\n",
              " 0.014305,\n",
              " 0.06804831,\n",
              " -0.008052531,\n",
              " 0.09061459,\n",
              " -0.024711937,\n",
              " 0.03473116,\n",
              " -0.059176326,\n",
              " 0.04100931,\n",
              " 0.035470266,\n",
              " 0.0013704862,\n",
              " -0.013956577,\n",
              " -0.077876054,\n",
              " -0.0330358,\n",
              " -0.0040769875,\n",
              " -0.034189425,\n",
              " 0.059057374,\n",
              " 0.06484688,\n",
              " 0.012517746,\n",
              " 0.0136308195,\n",
              " -0.0398553,\n",
              " 0.0743837,\n",
              " -0.037992813,\n",
              " 0.05327752,\n",
              " 0.026508018,\n",
              " -0.06448371,\n",
              " -0.07445219,\n",
              " 0.038217496,\n",
              " 0.059006996,\n",
              " 0.024826704,\n",
              " 0.041677125,\n",
              " -0.032546345,\n",
              " -0.00087021926,\n",
              " -0.027123814,\n",
              " -0.009504686,\n",
              " 0.013922258,\n",
              " 0.06470537,\n",
              " 0.01420557,\n",
              " 0.016170053,\n",
              " -0.021575375,\n",
              " -0.048223536,\n",
              " -0.0075398334,\n",
              " 0.032872368,\n",
              " 0.0074171866,\n",
              " -0.010398529,\n",
              " 0.08522549,\n",
              " -0.031736545,\n",
              " -0.03365431,\n",
              " 0.036757212,\n",
              " -0.04206843,\n",
              " -0.09566453,\n",
              " -0.0611197,\n",
              " -0.060269654,\n",
              " -0.047690026,\n",
              " -0.009566139,\n",
              " -0.04221254,\n",
              " 0.06752559,\n",
              " 0.048724454,\n",
              " 0.032867797,\n",
              " 0.03777867,\n",
              " -0.056828856,\n",
              " 0.020239173,\n",
              " 0.026053553,\n",
              " 0.05193865,\n",
              " -0.042716827,\n",
              " 0.05255447,\n",
              " -0.014181823,\n",
              " -0.014946587,\n",
              " 0.052895803,\n",
              " 0.015462572,\n",
              " -0.016426696,\n",
              " -0.00250208,\n",
              " -0.041010875,\n",
              " 0.037278134,\n",
              " -0.08603215,\n",
              " -0.019642135,\n",
              " -0.007410547,\n",
              " -0.06554093,\n",
              " -0.0347248,\n",
              " -0.05442846,\n",
              " -0.017522166,\n",
              " 0.016616553,\n",
              " 0.04271963,\n",
              " -0.043614198,\n",
              " 0.010626285,\n",
              " 0.09168475,\n",
              " -0.08565951,\n",
              " 0.00804008,\n",
              " 0.030776983,\n",
              " 0.045766786,\n",
              " -0.027179206,\n",
              " -0.048247382,\n",
              " -0.024212947,\n",
              " 0.06702163,\n",
              " -0.025103599,\n",
              " -0.021025253,\n",
              " 0.0142642055,\n",
              " 0.039221704,\n",
              " 0.024723506,\n",
              " -0.03856429,\n",
              " 0.04816922,\n",
              " -0.09470423,\n",
              " 0.0034542934,\n",
              " 0.025680194,\n",
              " 0.014168479,\n",
              " 0.029040987,\n",
              " -0.04855102,\n",
              " -0.03012122,\n",
              " -0.07591476,\n",
              " 0.09269827,\n",
              " 0.018363282,\n",
              " -0.012971344,\n",
              " 0.0049771224,\n",
              " 0.08525236,\n",
              " 0.024724385,\n",
              " -0.07239878,\n",
              " 0.06132726,\n",
              " 0.04122184,\n",
              " 0.0032983364,\n",
              " 0.08957489,\n",
              " 0.02336793,\n",
              " -0.08085133,\n",
              " -0.043832522,\n",
              " 0.002768359,\n",
              " 0.032906804,\n",
              " 0.053709418,\n",
              " 0.0002437707,\n",
              " -0.009246423,\n",
              " 0.04085756,\n",
              " 0.090176634,\n",
              " 0.0076497453,\n",
              " -0.061543554,\n",
              " 0.036947366,\n",
              " 0.01524924,\n",
              " -0.07507873,\n",
              " -0.051103592,\n",
              " 0.007430415,\n",
              " 0.039828867,\n",
              " -0.05218298,\n",
              " 0.016591137,\n",
              " 0.047635607,\n",
              " -0.036382783,\n",
              " 0.009306795,\n",
              " 0.07782059,\n",
              " 0.014442201,\n",
              " -0.007928436,\n",
              " -0.049274214,\n",
              " -0.012850522,\n",
              " 0.006896913,\n",
              " -0.02100338,\n",
              " -0.018641142,\n",
              " 1.9823034e-05,\n",
              " -0.0013293597,\n",
              " -0.0033476823,\n",
              " -0.023130387,\n",
              " 0.00963367,\n",
              " -0.019277213,\n",
              " -0.0043646568,\n",
              " 0.089263305,\n",
              " 0.08189173,\n",
              " -0.0069325427,\n",
              " -0.020145396,\n",
              " 0.06387583,\n",
              " 0.044940293,\n",
              " -0.00021684573,\n",
              " 0.06298004,\n",
              " 0.011507491,\n",
              " 0.01949955,\n",
              " -0.054554142,\n",
              " -0.0012667697,\n",
              " -0.023637496,\n",
              " 0.024681665,\n",
              " -0.015075246,\n",
              " -0.07516314,\n",
              " -0.02280592,\n",
              " 0.024869632,\n",
              " -0.039085414,\n",
              " 0.014271055,\n",
              " 0.0015384754,\n",
              " -0.014880021,\n",
              " -0.026253242,\n",
              " 0.05921649,\n",
              " -0.0135907,\n",
              " -0.053316522,\n",
              " 0.0046304446,\n",
              " 0.03056387,\n",
              " 0.05752377,\n",
              " -0.04624583,\n",
              " 0.0059916805,\n",
              " -0.041335925,\n",
              " -0.053242404,\n",
              " 0.010293286,\n",
              " 0.0028356167,\n",
              " -0.03654642,\n",
              " 0.04214458,\n",
              " 0.031362426,\n",
              " 0.047557987,\n",
              " -0.0002899174,\n",
              " 0.038133662,\n",
              " -0.014322084,\n",
              " 0.026184633,\n",
              " -0.046732645,\n",
              " -0.031365145,\n",
              " -0.0032904863,\n",
              " -0.04551777,\n",
              " -0.04892878,\n",
              " 0.027952371,\n",
              " -0.00923761,\n",
              " -0.010706074,\n",
              " -0.06609405,\n",
              " 0.08069964,\n",
              " -0.01122321,\n",
              " 0.00516626,\n",
              " -0.09037495,\n",
              " -0.03955627,\n",
              " -0.044462826,\n",
              " -0.09489008,\n",
              " -0.027430817,\n",
              " 0.046227437,\n",
              " -0.012633259,\n",
              " 0.02680822,\n",
              " -0.03821559,\n",
              " -0.015047111,\n",
              " -0.045151677,\n",
              " 0.008093589,\n",
              " -0.050421953,\n",
              " -0.022993183,\n",
              " 0.04054793,\n",
              " 0.0018783584,\n",
              " 0.030372133,\n",
              " 0.010735654,\n",
              " 0.039090924,\n",
              " 0.006051657,\n",
              " 0.06365998,\n",
              " -0.026518947,\n",
              " 0.0037383772,\n",
              " 0.088657014,\n",
              " 0.037825476,\n",
              " -0.043257594,\n",
              " 0.0026066543,\n",
              " -0.008545613,\n",
              " -0.048154455,\n",
              " -0.03737025,\n",
              " -0.066462666,\n",
              " -0.0066325786,\n",
              " -0.05110478,\n",
              " 0.05897866,\n",
              " 0.064849496,\n",
              " 0.08464632,\n",
              " -0.032982543,\n",
              " -0.03865525,\n",
              " -0.01970872,\n",
              " 0.06793495,\n",
              " -0.0068957335,\n",
              " 0.05056522,\n",
              " 0.020509684,\n",
              " 0.06462746,\n",
              " -0.027344197,\n",
              " -0.0004981603,\n",
              " -0.031887468,\n",
              " 0.0025320144,\n",
              " -0.019362016,\n",
              " 0.03475998,\n",
              " 0.008465706,\n",
              " 0.052640658,\n",
              " -0.03201429,\n",
              " -0.03659123,\n",
              " 0.001018368,\n",
              " -0.021588786,\n",
              " -0.043693226,\n",
              " -0.002113749,\n",
              " -0.028573323,\n",
              " -0.015304496,\n",
              " 0.0034776633,\n",
              " -0.03066208,\n",
              " 0.028871922,\n",
              " -0.06468154,\n",
              " 0.01093023,\n",
              " -0.0032681269,\n",
              " 0.0048462343,\n",
              " 0.09461817,\n",
              " 0.018394759,\n",
              " 0.020020485,\n",
              " 0.049092006,\n",
              " 0.033773508,\n",
              " -0.0013458969,\n",
              " -0.0260213,\n",
              " -0.012440168,\n",
              " 0.065566584,\n",
              " 0.09221671,\n",
              " 0.036078464,\n",
              " -0.092006005,\n",
              " -0.007163256,\n",
              " 0.002045815,\n",
              " 0.023508582,\n",
              " -0.04752647,\n",
              " 0.004778163,\n",
              " -0.08767312,\n",
              " 0.038448296,\n",
              " -0.08696722,\n",
              " -0.011333853,\n",
              " -0.029978618,\n",
              " -0.07137625,\n",
              " -0.0071794144,\n",
              " 0.060631383,\n",
              " 0.026199847,\n",
              " 0.007628865,\n",
              " 0.009155058,\n",
              " 0.023441656,\n",
              " 0.011183538,\n",
              " 0.020197785,\n",
              " 0.04909227,\n",
              " -0.015021532,\n",
              " -0.023124604,\n",
              " -0.015620726,\n",
              " 0.010226107,\n",
              " -0.04785519,\n",
              " 0.060538888,\n",
              " -0.050634127,\n",
              " 0.08421009,\n",
              " 0.07253908,\n",
              " -0.039140396,\n",
              " -0.09800458,\n",
              " -0.031977188,\n",
              " 0.008537036,\n",
              " 0.08333068,\n",
              " -0.015161067,\n",
              " -0.02016476,\n",
              " -0.05383038,\n",
              " -0.0062976712,\n",
              " -0.02265368,\n",
              " 0.008003466,\n",
              " -0.053206235,\n",
              " -0.08491805,\n",
              " 0.0037881967,\n",
              " 0.04691645,\n",
              " -0.01001199,\n",
              " 0.040583376,\n",
              " 0.06571731,\n",
              " 0.0027311617,\n",
              " 0.042798266,\n",
              " -0.068183176,\n",
              " 0.006626262,\n",
              " -0.002576092,\n",
              " -0.03183758,\n",
              " -0.09432449,\n",
              " -0.009646263,\n",
              " 0.055257875,\n",
              " 0.023778258,\n",
              " -0.07766074,\n",
              " -0.07254838,\n",
              " 0.027229056,\n",
              " -0.017595148,\n",
              " 0.025870025,\n",
              " 0.016192826,\n",
              " 0.07642939,\n",
              " 0.043433305,\n",
              " -0.053878274,\n",
              " -0.017245943,\n",
              " 0.027337996,\n",
              " -0.004994064,\n",
              " 0.0034841523,\n",
              " 0.045495514,\n",
              " -0.040584162,\n",
              " -0.0043729497,\n",
              " -0.05933648,\n",
              " 0.07231312,\n",
              " -0.07670364,\n",
              " -0.016196797,\n",
              " -0.011034444,\n",
              " 0.014505254,\n",
              " -0.010587295,\n",
              " -0.008290566,\n",
              " -0.04354107,\n",
              " -0.08231347,\n",
              " 0.0713264,\n",
              " -0.051354107,\n",
              " -0.038453143,\n",
              " 0.057818152,\n",
              " 0.009485539,\n",
              " 0.07598647,\n",
              " 0.026258206,\n",
              " 0.0068701557,\n",
              " -0.010953187,\n",
              " -0.063336015,\n",
              " -0.013253805,\n",
              " 0.01657972,\n",
              " -0.019002866,\n",
              " 0.008545843,\n",
              " -0.03920249,\n",
              " -0.01468655,\n",
              " -0.038810786,\n",
              " 0.009947682,\n",
              " 0.08938672,\n",
              " 0.019866852,\n",
              " 0.035274476,\n",
              " -0.044154957,\n",
              " 0.027522756,\n",
              " -0.019371532,\n",
              " 0.014447351,\n",
              " 0.036811,\n",
              " 0.005699189,\n",
              " -0.034764122,\n",
              " -0.029867468,\n",
              " -0.08349824,\n",
              " -0.08575829,\n",
              " -0.022085262,\n",
              " 0.020713298,\n",
              " -0.009739142,\n",
              " 0.06796973,\n",
              " -0.008882533,\n",
              " 0.09031486,\n",
              " -0.03137426,\n",
              " 0.043331787,\n",
              " -0.049501892,\n",
              " 0.017212866,\n",
              " -0.035052802,\n",
              " 0.061659284,\n",
              " 0.016786745,\n",
              " -0.03807234,\n",
              " -0.041688483,\n",
              " -0.052141495,\n",
              " 0.059910685,\n",
              " 0.028142681,\n",
              " 0.057019394,\n",
              " 0.019282093,\n",
              " -0.043448735,\n",
              " 0.0125777675,\n",
              " -0.010163772,\n",
              " -0.033035435,\n",
              " 0.08012544,\n",
              " -0.036249723,\n",
              " 0.0043285666,\n",
              " 0.05903524,\n",
              " -0.015241772,\n",
              " -0.055041075,\n",
              " -0.0357986,\n",
              " -0.065500766,\n",
              " -0.035066802,\n",
              " 0.014545085,\n",
              " 0.014398726,\n",
              " 0.019431876,\n",
              " -0.037329186,\n",
              " -0.07487203,\n",
              " 0.06470622,\n",
              " -0.018455302,\n",
              " 0.008596132,\n",
              " -0.015713135,\n",
              " -0.08393278,\n",
              " -0.022445697,\n",
              " 0.0066948654,\n",
              " -0.028612122,\n",
              " -0.038499735,\n",
              " 0.052180775,\n",
              " -0.052407708,\n",
              " 0.043751445,\n",
              " 0.00462679,\n",
              " -0.03627411,\n",
              " 0.085677184,\n",
              " -0.039329614,\n",
              " 0.004468519,\n",
              " -0.022871222,\n",
              " -0.002545784,\n",
              " -0.020290587,\n",
              " -0.056177616,\n",
              " 0.013245334,\n",
              " 0.036794633,\n",
              " 0.0153457625,\n",
              " -0.09555303,\n",
              " -0.019618284,\n",
              " -0.031786617,\n",
              " -0.017028533,\n",
              " -0.016580192,\n",
              " 0.011398219,\n",
              " 0.04808327,\n",
              " 0.03402942,\n",
              " -0.019358013,\n",
              " 0.015455194,\n",
              " -0.0022505429,\n",
              " 0.0062149535,\n",
              " -0.053798694,\n",
              " 0.04500907,\n",
              " -0.01809596,\n",
              " 0.05387307,\n",
              " -0.0028296781,\n",
              " 0.026372194,\n",
              " 0.033327952,\n",
              " -0.014601675,\n",
              " -0.0005448199,\n",
              " 0.064187825,\n",
              " 0.011012482,\n",
              " 0.025155848,\n",
              " -0.0194491,\n",
              " 0.022727486,\n",
              " -0.019003786,\n",
              " -0.03512331,\n",
              " 0.092659734,\n",
              " 0.06450052,\n",
              " -0.052811053,\n",
              " -0.0118711125,\n",
              " 0.019573497,\n",
              " -0.013149557,\n",
              " -0.08143645,\n",
              " 0.0417138,\n",
              " 0.036642384,\n",
              " 0.052980747,\n",
              " -0.06675615,\n",
              " 0.06276021,\n",
              " -0.03357461,\n",
              " -0.027231885,\n",
              " 0.013551136,\n",
              " -0.026508993,\n",
              " 0.018760575,\n",
              " -0.032196462,\n",
              " 0.026300937,\n",
              " 0.066673584,\n",
              " -0.024260433,\n",
              " -0.05335634,\n",
              " 0.0045202165,\n",
              " -0.0047219107,\n",
              " -0.03030478,\n",
              " -0.0016544771,\n",
              " -0.005804372,\n",
              " 0.053179156,\n",
              " -0.049727,\n",
              " 0.00051598443,\n",
              " -0.07017594,\n",
              " 0.034939576,\n",
              " -0.06723868,\n",
              " 0.0048615797,\n",
              " -0.028315393,\n",
              " -0.02678354,\n",
              " -0.05215626,\n",
              " 0.060641814,\n",
              " -0.07226576,\n",
              " 0.04537146,\n",
              " -0.015241823,\n",
              " 0.022246258,\n",
              " -0.019987514,\n",
              " -0.012654421,\n",
              " 0.010730983,\n",
              " 0.01566275,\n",
              " 0.0331733,\n",
              " 0.0011248399,\n",
              " -0.04156453,\n",
              " -0.045997057,\n",
              " 0.051966995,\n",
              " -0.0276226,\n",
              " 0.018727731,\n",
              " 0.023425128,\n",
              " 0.01030261,\n",
              " -0.027242929,\n",
              " 0.06812712,\n",
              " -0.052604973,\n",
              " 0.04988427,\n",
              " 0.0011112043,\n",
              " -0.008723672,\n",
              " -0.016864536,\n",
              " 0.058746662,\n",
              " -0.006379597,\n",
              " -0.058577415,\n",
              " -0.0035231833,\n",
              " -0.0072899023,\n",
              " 0.0636725,\n",
              " 0.006915287,\n",
              " 0.024940459,\n",
              " 0.03767139,\n",
              " -0.039655227,\n",
              " 0.029205445,\n",
              " -0.020646306,\n",
              " 0.067795806,\n",
              " 0.051639672,\n",
              " 0.079614006,\n",
              " -0.048124995,\n",
              " -0.050564107,\n",
              " -0.07551402,\n",
              " -0.012904607,\n",
              " 0.014797446,\n",
              " -0.023462132,\n",
              " 0.02281776,\n",
              " 0.019465864,\n",
              " -0.0011878172,\n",
              " -0.03528334,\n",
              " -0.048476946,\n",
              " 0.026245192,\n",
              " 0.041760333,\n",
              " -0.01438945,\n",
              " 0.091316685,\n",
              " -0.0110439,\n",
              " 0.022453416,\n",
              " -0.0061984896,\n",
              " 0.059846114,\n",
              " -0.084267,\n",
              " -0.059161585,\n",
              " -0.011131099,\n",
              " 0.019140353,\n",
              " 0.03488854,\n",
              " 0.0147942575,\n",
              " 0.051901538,\n",
              " -0.0033283585,\n",
              " 0.025812393,\n",
              " -0.095068775,\n",
              " -0.0072156168,\n",
              " 0.05721369,\n",
              " -0.043304283,\n",
              " 3.6761776e-05,\n",
              " -0.023340145,\n",
              " 0.061133683,\n",
              " 0.0027595726,\n",
              " 0.030236766,\n",
              " -0.038100723,\n",
              " -0.04948091,\n",
              " -0.0475855,\n",
              " -0.0034018953,\n",
              " 0.008122499,\n",
              " 0.012139586,\n",
              " -0.021794591,\n",
              " -0.010207449,\n",
              " -0.004945963,\n",
              " -0.06877678,\n",
              " 0.0032073115,\n",
              " 0.028641963,\n",
              " 0.040345497,\n",
              " -0.036483843,\n",
              " 0.06267802,\n",
              " -0.09682321,\n",
              " 0.021287495,\n",
              " 0.015377021,\n",
              " -0.029781539,\n",
              " -0.05093456,\n",
              " 0.020481026,\n",
              " 0.043511618,\n",
              " 0.050520808,\n",
              " 0.021300761,\n",
              " -0.031796496,\n",
              " 0.054291975,\n",
              " 0.062149674,\n",
              " -0.017601378,\n",
              " 0.046672147,\n",
              " 0.079756655,\n",
              " 0.0052662054,\n",
              " -0.06020484,\n",
              " -0.024409546,\n",
              " 0.05756509,\n",
              " 0.048638444,\n",
              " -0.0028193959,\n",
              " -0.07570073,\n",
              " 0.051110428,\n",
              " -0.06503559,\n",
              " -0.011185334,\n",
              " -0.006992171,\n",
              " -0.017101273,\n",
              " 0.016148148,\n",
              " -0.04535232,\n",
              " -0.014018016,\n",
              " 0.010135985,\n",
              " 0.026351174,\n",
              " 0.05299834,\n",
              " 0.042215273,\n",
              " 0.034857634,\n",
              " -0.03676031,\n",
              " -0.056578707,\n",
              " -0.015903478,\n",
              " -0.031155244,\n",
              " -0.036211487,\n",
              " 0.0017622396,\n",
              " -0.05676741,\n",
              " -0.038785186,\n",
              " 0.0027027987,\n",
              " -0.0043936516,\n",
              " -0.0031767064,\n",
              " 0.007755977,\n",
              " -0.057406534,\n",
              " 0.0102484105,\n",
              " -0.0029653034,\n",
              " 0.010550437,\n",
              " 0.041809198,\n",
              " 0.09114407,\n",
              " 0.034438286,\n",
              " -0.08993571,\n",
              " -0.0067692646,\n",
              " 0.013032074,\n",
              " 0.08869853,\n",
              " -0.023284402,\n",
              " 0.033441644,\n",
              " -0.020606687,\n",
              " 0.0037786637,\n",
              " -0.005208736,\n",
              " -0.064673476,\n",
              " 0.0043098778,\n",
              " 0.021099376,\n",
              " 0.018165529,\n",
              " -0.038982954,\n",
              " -0.039189216,\n",
              " -0.024589524,\n",
              " 0.018367618,\n",
              " -0.065436244,\n",
              " -0.022599794,\n",
              " 0.051242378,\n",
              " -0.040663164,\n",
              " 0.013542629,\n",
              " 0.05514421,\n",
              " 0.025999589,\n",
              " -0.07469342,\n",
              " 0.011368173,\n",
              " -0.066030085,\n",
              " 0.031735145,\n",
              " -0.00010961471,\n",
              " -0.037868004,\n",
              " 0.09176049,\n",
              " 0.0007194054,\n",
              " -0.04282623,\n",
              " 0.001760783,\n",
              " -0.009862618,\n",
              " 0.020990893,\n",
              " -0.07069659,\n",
              " -0.0672703,\n",
              " 0.013233696,\n",
              " 0.04366438,\n",
              " -0.020243688,\n",
              " 0.07995937,\n",
              " -0.0362399,\n",
              " -0.013233303,\n",
              " 0.028469985,\n",
              " -0.025682494,\n",
              " 0.0105301915,\n",
              " 0.06882225,\n",
              " -0.022992648,\n",
              " -0.06995227,\n",
              " -0.056445785,\n",
              " -0.0062215123,\n",
              " -0.020328458,\n",
              " -0.016419185,\n",
              " 0.023818012,\n",
              " -0.06865529,\n",
              " 0.048353117,\n",
              " 0.008559766,\n",
              " -0.0011755343,\n",
              " -0.07773188,\n",
              " 0.00825547,\n",
              " 0.07035929,\n",
              " 0.056478392,\n",
              " -0.01795839,\n",
              " 0.046263985,\n",
              " -0.06602422,\n",
              " 0.043630045,\n",
              " 0.03617811,\n",
              " -0.02835665,\n",
              " 0.03404825,\n",
              " 0.032970317,\n",
              " -0.08714361,\n",
              " -0.026311895,\n",
              " -0.016886089,\n",
              " 0.0027426446,\n",
              " -0.06901861,\n",
              " -0.025287965,\n",
              " -0.027931482,\n",
              " -0.036579635,\n",
              " 0.022985421,\n",
              " 0.0698867,\n",
              " -0.014784137,\n",
              " -0.011362917,\n",
              " 0.034744203,\n",
              " 0.03006806,\n",
              " -0.008040342,\n",
              " -0.00059044245,\n",
              " 0.01637959,\n",
              " -0.05095131,\n",
              " 0.028694836,\n",
              " -0.038463555,\n",
              " 0.07034434,\n",
              " 0.019142693,\n",
              " -0.04604092,\n",
              " 0.033733685,\n",
              " 0.059159786,\n",
              " -0.010357029,\n",
              " -0.03685939,\n",
              " 0.05687225,\n",
              " -0.0062720007,\n",
              " -0.026026754,\n",
              " 0.017460896,\n",
              " 0.026599243,\n",
              " -0.030509043,\n",
              " 0.008975053,\n",
              " -0.02859771,\n",
              " -0.059940476,\n",
              " 0.027124926,\n",
              " 0.03122413,\n",
              " 0.07798792,\n",
              " 0.04997989,\n",
              " -0.001892115,\n",
              " 0.0106319105,\n",
              " -0.0065685967,\n",
              " 0.052246567,\n",
              " 0.006713332,\n",
              " 0.023651076,\n",
              " 0.004677703,\n",
              " -0.06836426,\n",
              " 0.07037844,\n",
              " -0.053221382,\n",
              " -0.07216833,\n",
              " 0.04551445,\n",
              " -0.0049563022,\n",
              " 0.015866645,\n",
              " 0.017425712,\n",
              " -0.037075423,\n",
              " -0.007948176,\n",
              " 0.0629771,\n",
              " 0.049285635,\n",
              " -0.018357998,\n",
              " -0.016211659,\n",
              " 0.011263247,\n",
              " -0.048979606,\n",
              " 0.006154792,\n",
              " -0.0072472095,\n",
              " -0.0852583,\n",
              " -0.040031027,\n",
              " 0.025574982,\n",
              " -0.029817266,\n",
              " 0.011226757,\n",
              " 0.0066240155,\n",
              " -0.042723782,\n",
              " 0.05266965,\n",
              " -0.046778068,\n",
              " 0.024642091,\n",
              " -0.018799944,\n",
              " -0.04468042,\n",
              " 0.05404371,\n",
              " 0.0432814,\n",
              " 0.00058647536,\n",
              " -0.047724135,\n",
              " -0.06086902,\n",
              " -0.010473418,\n",
              " 0.018775333,\n",
              " 0.056246,\n",
              " -0.07946637,\n",
              " -0.007082893,\n",
              " -0.006003381,\n",
              " 0.012113053,\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcWIkVj_EhHn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32a8d5bf-7acd-4cda-b87c-3ce010bda38d"
      },
      "source": [
        "len(w)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19008"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfk3Tu6BGkLM"
      },
      "source": [
        "# vector to matrix conversion function for weights matrix\n",
        "def vect_to_mat(w):\n",
        "  \n",
        "\n",
        "  for i in range(9):\n",
        "    for j in range(256):\n",
        "      W0[i][j]=w[(i*j)+j]\n",
        "  for i in range(64):\n",
        "    for j in range(256):\n",
        "      W1[i][j]=w[(i*j)+j+(256*9)]\n",
        "  W2=[]\n",
        "  W21=[]\n",
        "  for i in range(256):\n",
        "    value=w[i+(256*9)+(256*64)]\n",
        "    W21.append(value)\n",
        "  W2=np.asarray(W21) \n",
        "\n",
        "  for i in range(64):\n",
        "    for j in range(1):\n",
        "      W3[i][j]=w[(i*j)+j+(256*9)+(256*64)+256]\n",
        "  Weight=(np.asarray(W0),np.asarray(W1),(W2),np.asarray(W3))\n",
        "  return Weight "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLnBgZLDOnY7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "67cf6b7b-b7c6-4eb1-b397-656f8c60305c"
      },
      "source": [
        "Weight=vect_to_mat(w)\n",
        "Weight"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.09247728,  0.00353939,  0.00975701, ..., -0.02421295,\n",
              "          0.06702163, -0.0251036 ],\n",
              "        [-0.09247728,  0.00975701, -0.01684218, ..., -0.09432449,\n",
              "          0.05525788, -0.07766074],\n",
              "        [-0.09247728, -0.00131249, -0.01982059, ...,  0.05190154,\n",
              "         -0.09506878, -0.04330428],\n",
              "        ...,\n",
              "        [-0.09247728, -0.08686286, -0.02457468, ...,  0.06610964,\n",
              "         -0.02940355,  0.03515362],\n",
              "        [-0.09247728,  0.01339906, -0.05490708, ..., -0.07850296,\n",
              "          0.0174134 ,  0.01940314],\n",
              "        [-0.09247728,  0.03166791,  0.04904716, ...,  0.05486101,\n",
              "          0.02895169, -0.00088773]], dtype=float32),\n",
              " array([[ 0.02458596,  0.04555072,  0.00082149, ..., -0.04373634,\n",
              "         -0.01029696, -0.0250397 ],\n",
              "        [ 0.02458596,  0.00082149, -0.07695917, ...,  0.02984568,\n",
              "         -0.06861866, -0.00040471],\n",
              "        [ 0.02458596, -0.04005281,  0.0387088 , ..., -0.04845909,\n",
              "          0.01492041, -0.02788559],\n",
              "        ...,\n",
              "        [ 0.02458596, -0.06726754, -0.14158587, ..., -0.03646819,\n",
              "          0.10091905, -0.11722989],\n",
              "        [ 0.02458596, -0.07186067, -0.10226195, ...,  0.09416635,\n",
              "         -0.06375491,  0.07006232],\n",
              "        [ 0.02458596,  0.02068018,  0.01465751, ...,  0.00344269,\n",
              "          0.07479729, -0.02627036]], dtype=float32),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.], dtype=float32),\n",
              " array([[-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739],\n",
              "        [-0.234739]], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoFM-uQMQYrc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "ecc1f10b-211f-46da-a2d7-7a68f9cb026c"
      },
      "source": [
        "#Training the model\n",
        "model.set_weights(Weight)\n",
        "history = model.fit(train_x, train_y, epochs=1, batch_size=15058, validation_data=(valid_x, valid_y), verbose=1, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 32831 samples, validate on 4377 samples\n",
            "Epoch 1/1\n",
            "32831/32831 [==============================] - 2s 59us/step - loss: 0.3996 - val_loss: 0.2676\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6ofktPyUZxL"
      },
      "source": [
        "# model.save('modelw0multiple.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7lvqaR7n9XH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6bcb39d5-2fea-4bbd-b5c5-e63f635a8f04"
      },
      "source": [
        "#Rescaling the data\n",
        "yhat = model.predict(test_x)\n",
        "\n",
        "inv_yhat = scale_y.inverse_transform(yhat)\n",
        "\n",
        "inv_y = scale_y.inverse_transform(test_y)\n",
        "\n",
        "#Finding the accuracy with RMSE function\n",
        "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
        "print('Test RMSE: %.3f' % rmse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test RMSE: 315.440\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gCtOqnXRgMh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aeaa66c7-4d32-4a43-d99b-528495df9fc7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import csv\n",
        "import random\n",
        "from math import sqrt\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "# INITIALIZATION\n",
        "population_size = 10\n",
        "max_generation = 10\n",
        "_lambda = 1.5\n",
        "dimension = 19008\n",
        "max_domain = 0.1\n",
        "min_domain = -0.1\n",
        "step_size_cons = 0.01\n",
        "Pa = 0.3\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "# CALCULATING ACCURACY USING r2 SCORE (since this model is currently getting used as a regression model)\n",
        "def accuracy(array, data, labels):\n",
        "    WEight=vect_to_mat(array)\n",
        "    model.set_weights(WEight)\n",
        "    model.compile(loss='mae', optimizer=Adam(lr=0.01))\n",
        "    history = model.fit(train_x, train_y, epochs=50, batch_size=15058, validation_data=(valid_x, valid_y), verbose=1, shuffle=False)\n",
        "    yhat = model.predict(train_x)\n",
        "\n",
        "    inv_yhat = scale_y.inverse_transform(yhat)\n",
        "\n",
        "    inv_y = scale_y.inverse_transform(train_y)\n",
        "    acc = metrics.r2_score(inv_y, inv_yhat)\n",
        "    return acc\n",
        "\n",
        "# OBJECTIVE FUNCTION\n",
        "def rmse(array, data, labels):  # CONVERTING THIS FUNCTION INTO rmse FUNC OF ANN\n",
        "    WEight=vect_to_mat(array)\n",
        "    model.set_weights(WEight)\n",
        "    model.compile(loss='mae', optimizer=Adam(lr=0.01))\n",
        "    history = model.fit(train_x, train_y, epochs=50, batch_size=15058, validation_data=(valid_x, valid_y), verbose=1, shuffle=False)\n",
        "    yhat = model.predict(train_x)\n",
        "\n",
        "    inv_yhat = scale_y.inverse_transform(yhat)\n",
        "\n",
        "    inv_y = scale_y.inverse_transform(train_y)\n",
        "\n",
        "    fitness = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
        "    # fitness = sqrt(metrics.mean_squared_error(x_actual, y_predicted))\n",
        "    return fitness\n",
        "\n",
        "# LEVY FLIGHT\n",
        "def levy_flight(Lambda):\n",
        "    sigma1 = np.power((math.gamma(1 + Lambda) * np.sin((np.pi * Lambda) / 2)) \\\n",
        "                      / math.gamma((1 + Lambda) / 2) * np.power(2, (Lambda - 1) / 2), 1 / Lambda)\n",
        "    sigma2 = 1\n",
        "    u = np.random.normal(0, sigma1, size=dimension)\n",
        "    v = np.random.normal(0, sigma2, size=dimension)\n",
        "    step = u / np.power(np.fabs(v), 1 / Lambda)\n",
        "\n",
        "    return step\n",
        "\n",
        "class Individual:\n",
        "    def __init__(self, data, labels):\n",
        "        self.__position = np.random.rand(dimension) * (max_domain - min_domain) + min_domain\n",
        "        self.__fitness = rmse(self.__position, data, labels)\n",
        "\n",
        "    def get_position(self):\n",
        "        return self.__position\n",
        "\n",
        "    def get_fitness(self):\n",
        "        return self.__fitness\n",
        "\n",
        "    def set_position(self, position):\n",
        "        self.__position = position\n",
        "\n",
        "    def set_fitness(self, fitness):\n",
        "        self.__fitness = fitness\n",
        "\n",
        "    def abandon(self, data, labels):\n",
        "        # abandon some variables\n",
        "        for i in range(dimension): \n",
        "            p = np.random.rand()\n",
        "            if p < Pa:\n",
        "                self.__position[i] = np.random.rand() * (max_domain - min_domain) + min_domain\n",
        "        self.__fitness = rmse(self.__position, data, labels)\n",
        "\n",
        "def main():\n",
        "\n",
        "    # RANDOMLY CREATING HOSTS\n",
        "cs_list = []\n",
        "for i in range(population_size):\n",
        "    cs_list.append(Individual(train_x, train_y))\n",
        "\n",
        "\n",
        "    # SORT TO GET THE BEST FITNESS\n",
        "cs_list = sorted(cs_list, key=lambda ID: ID.get_fitness())\n",
        "\n",
        "best_fitness = cs_list[0].get_fitness()\n",
        "best_position = cs_list[0].get_position()\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "    # INITIAL POPULATION DISTRIBUTION\n",
        "ax1 = fig.add_subplot(131)\n",
        "for i in range(population_size):\n",
        "        ax1.scatter([cs_list[i].get_position()[0]], [cs_list[i].get_position()[1]])\n",
        "ax1.set_title('Initial Population Distributtion')\n",
        "ax1.set_xlabel('x-axis')\n",
        "ax1.set_ylabel('y-axis')\n",
        "\n",
        "ax3 = fig.add_subplot(133)\n",
        "\n",
        "t = 1\n",
        "while t < max_generation:\n",
        "\n",
        "        # GENERATING NEW SOLUTIONS\n",
        "        for i in range(population_size):\n",
        "\n",
        "            # CHOOSING A RANDOM CUCKOO (say i)\n",
        "            i = np.random.randint(low=0, high=population_size)\n",
        "\n",
        "            # SETTING ITS POSITION USING LEVY FLIGHT\n",
        "            position = (cs_list[i].get_position())+(step_size_cons*levy_flight(_lambda))\n",
        "\n",
        "            # Simple Boundary Rule\n",
        "            for k in range(dimension):\n",
        "                if position[k] > max_domain:\n",
        "                    position[k] = max_domain\n",
        "                if position[k] < min_domain:\n",
        "                    position[k] = min_domain\n",
        "\n",
        "            cs_list[i].set_position(position)\n",
        "            cs_list[i].set_fitness(rmse(cs_list[i].get_position(), train_x, train_y))\n",
        "\n",
        "            # CHOOSING A RANDOM HOST (say j)\n",
        "            j = np.random.randint(0, population_size)\n",
        "            while j == i:  # random id[say j] ≠ i\n",
        "                j = np.random.randint(0, population_size)\n",
        "\n",
        "            # RELAXATION\n",
        "            if cs_list[j].get_fitness() > cs_list[i].get_fitness():\n",
        "                cs_list[j].set_position(cs_list[i].get_position())\n",
        "                cs_list[j].set_fitness(cs_list[i].get_fitness())\n",
        "\n",
        "        # SORT (to Keep Best)\n",
        "        cs_list = sorted(cs_list, key=lambda ID: ID.get_fitness())\n",
        "\n",
        "        # ABANDON SOLUTION (exclude the best)\n",
        "        for a in range(1, population_size):\n",
        "            r = np.random.rand()\n",
        "            if (r < Pa):\n",
        "                cs_list[a].abandon(train_x,train_y)\n",
        "\n",
        "        # RANKING THE CS LIST\n",
        "        cs_list = sorted(cs_list, key=lambda ID: ID.get_fitness())\n",
        "\n",
        "        # FIND THE CURRENT BEST\n",
        "        if cs_list[0].get_fitness() < best_fitness:\n",
        "            best_fitness = cs_list[0].get_fitness()\n",
        "            best_position = cs_list[0].get_position()\n",
        "\n",
        "        # PRINTING SOLUTION IN EACH ITERATION\n",
        "        print(\"iteration =\", t, \" best_fitness =\", best_fitness)\n",
        "\n",
        "        # FITNESS ARRAY\n",
        "        x.append(t)\n",
        "        y.append(best_fitness)\n",
        "\n",
        "        t += 1\n",
        "\n",
        "    # FITNESS PLOTTING\n",
        "ax3.plot(x, y)\n",
        "\n",
        "    # OPTIMIZED WEIGHTS\n",
        "print(\"\\nOptimized weights are \", *best_position)\n",
        "\n",
        "   \n",
        "\n",
        "\n",
        "print(\"RMSE of of final LSTM is \", rmse(best_position, test_x, test_y))\n",
        "print(\"Accuracy of final ANN is \", accuracy(best_position, test_x, test_y))\n",
        "\n",
        "    \n",
        "    # GRAPH FOR FITNESS\n",
        "ax3.set_title('Fitness Curve')\n",
        "ax3.set_xlabel('x-axis')\n",
        "ax3.set_ylabel('y-axis')\n",
        "\n",
        "    # FINAL POPULATION DISTRIBUTION\n",
        "ax2 = fig.add_subplot(132)\n",
        "for i in range(population_size):\n",
        "        ax2.scatter([cs_list[i].get_position()[0]], [cs_list[i].get_position()[1]])\n",
        "ax2.set_title('Final Population Distributtion after '+str(t)+' iterations')\n",
        "ax2.set_xlabel('x-axis')\n",
        "ax2.set_ylabel('y-axis')\n",
        "\n",
        "    # SHOWING GRAPH\n",
        "plt.show()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 32831 samples, validate on 4377 samples\n",
            "Epoch 1/50\n",
            "32831/32831 [==============================] - 1s 40us/step - loss: 0.2479 - val_loss: 0.1992\n",
            "Epoch 2/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.2158 - val_loss: 0.1745\n",
            "Epoch 3/50\n",
            "32831/32831 [==============================] - 0s 15us/step - loss: 0.1901 - val_loss: 0.1414\n",
            "Epoch 4/50\n",
            "32831/32831 [==============================] - 0s 15us/step - loss: 0.1474 - val_loss: 0.1349\n",
            "Epoch 5/50\n",
            "32831/32831 [==============================] - 1s 15us/step - loss: 0.1195 - val_loss: 0.0892\n",
            "Epoch 6/50\n",
            "32831/32831 [==============================] - 1s 15us/step - loss: 0.0960 - val_loss: 0.0701\n",
            "Epoch 7/50\n",
            "32831/32831 [==============================] - 1s 15us/step - loss: 0.0747 - val_loss: 0.0780\n",
            "Epoch 8/50\n",
            "32831/32831 [==============================] - 0s 15us/step - loss: 0.0721 - val_loss: 0.0674\n",
            "Epoch 9/50\n",
            "32831/32831 [==============================] - 1s 15us/step - loss: 0.0712 - val_loss: 0.0557\n",
            "Epoch 10/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0597 - val_loss: 0.0537\n",
            "Epoch 11/50\n",
            "32831/32831 [==============================] - 1s 15us/step - loss: 0.0555 - val_loss: 0.0485\n",
            "Epoch 12/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0499 - val_loss: 0.0550\n",
            "Epoch 13/50\n",
            "32831/32831 [==============================] - 1s 15us/step - loss: 0.0516 - val_loss: 0.0440\n",
            "Epoch 14/50\n",
            "32831/32831 [==============================] - 1s 15us/step - loss: 0.0463 - val_loss: 0.0668\n",
            "Epoch 15/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0591 - val_loss: 0.0478\n",
            "Epoch 16/50\n",
            "32831/32831 [==============================] - 1s 15us/step - loss: 0.0483 - val_loss: 0.0449\n",
            "Epoch 17/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0456 - val_loss: 0.0392\n",
            "Epoch 18/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0413 - val_loss: 0.0359\n",
            "Epoch 19/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0388 - val_loss: 0.0350\n",
            "Epoch 20/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0381 - val_loss: 0.0354\n",
            "Epoch 21/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0365 - val_loss: 0.0334\n",
            "Epoch 22/50\n",
            "32831/32831 [==============================] - 1s 15us/step - loss: 0.0356 - val_loss: 0.0305\n",
            "Epoch 23/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0339 - val_loss: 0.0279\n",
            "Epoch 24/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0319 - val_loss: 0.0296\n",
            "Epoch 25/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0328 - val_loss: 0.0275\n",
            "Epoch 26/50\n",
            "32831/32831 [==============================] - 1s 15us/step - loss: 0.0326 - val_loss: 0.0280\n",
            "Epoch 27/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0311 - val_loss: 0.0325\n",
            "Epoch 28/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0325 - val_loss: 0.0252\n",
            "Epoch 29/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0331 - val_loss: 0.0288\n",
            "Epoch 30/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0331 - val_loss: 0.0261\n",
            "Epoch 31/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0343 - val_loss: 0.0270\n",
            "Epoch 32/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0295 - val_loss: 0.0233\n",
            "Epoch 33/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0280 - val_loss: 0.0237\n",
            "Epoch 34/50\n",
            "32831/32831 [==============================] - 1s 15us/step - loss: 0.0280 - val_loss: 0.0256\n",
            "Epoch 35/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0286 - val_loss: 0.0257\n",
            "Epoch 36/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0291 - val_loss: 0.0300\n",
            "Epoch 37/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0294 - val_loss: 0.0221\n",
            "Epoch 38/50\n",
            "32831/32831 [==============================] - 1s 15us/step - loss: 0.0266 - val_loss: 0.0295\n",
            "Epoch 39/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0297 - val_loss: 0.0275\n",
            "Epoch 40/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0308 - val_loss: 0.0260\n",
            "Epoch 41/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0307 - val_loss: 0.0264\n",
            "Epoch 42/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0290 - val_loss: 0.0192\n",
            "Epoch 43/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0273 - val_loss: 0.0234\n",
            "Epoch 44/50\n",
            "32831/32831 [==============================] - 1s 15us/step - loss: 0.0253 - val_loss: 0.0212\n",
            "Epoch 45/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0238 - val_loss: 0.0187\n",
            "Epoch 46/50\n",
            "32831/32831 [==============================] - 0s 15us/step - loss: 0.0253 - val_loss: 0.0329\n",
            "Epoch 47/50\n",
            "32831/32831 [==============================] - 1s 15us/step - loss: 0.0321 - val_loss: 0.0360\n",
            "Epoch 48/50\n",
            "32831/32831 [==============================] - 1s 15us/step - loss: 0.0363 - val_loss: 0.0334\n",
            "Epoch 49/50\n",
            "32831/32831 [==============================] - 1s 16us/step - loss: 0.0310 - val_loss: 0.0257\n",
            "Epoch 50/50\n",
            "32831/32831 [==============================] - 1s 15us/step - loss: 0.0307 - val_loss: 0.0255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j84t2Q1bKMwh"
      },
      "source": [
        "model.save('cuckoo15_15.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S82Q_7yLkW9k"
      },
      "source": [
        "#Rescaling the data\n",
        "yhat = model.predict(test_x)\n",
        "\n",
        "inv_yhat = scale_y.inverse_transform(yhat)\n",
        "\n",
        "inv_y = scale_y.inverse_transform(test_y)\n",
        "#Finding the accuracy with RMSE function\n",
        "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
        "print('Test RMSE: %.3f' % rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAA-PfjxmknW"
      },
      "source": [
        "#Plotting the loss graphs\n",
        "plt.plot(inv_yhat[:],color='red',label='Predicted')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.plot(inv_y[:],label='Original value')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxmtfcYok2YS"
      },
      "source": [
        "#Saving the predicted file\n",
        "a=np.asmatrix(inv_y)\n",
        "b=np.asmatrix(inv_yhat)\n",
        "np.savetxt(\"actualcuckoo.csv\", a, delimiter=\",\")\n",
        "np.savetxt(\"predictcuckoo.csv\", b, delimiter=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}